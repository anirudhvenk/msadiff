{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b30b5a3-cdfc-4bd0-aadd-58987bc80cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "from Bio import SeqIO\n",
    "from typing import List, Tuple, Optional, Dict, NamedTuple, Union, Callable\n",
    "import string\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import squareform, pdist, cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "658d9ac4-d320-4525-b67a-9a8f31a81ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an efficient way to delete lowercase characters and insertion characters from a string\n",
    "deletekeys = dict.fromkeys(string.ascii_lowercase)\n",
    "deletekeys[\".\"] = None\n",
    "deletekeys[\"*\"] = None\n",
    "translation = str.maketrans(deletekeys)\n",
    "\n",
    "def read_sequence(filename: str) -> Tuple[str, str]:\n",
    "    \"\"\" Reads the first (reference) sequences from a fasta or MSA file.\"\"\"\n",
    "    record = next(SeqIO.parse(filename, \"fasta\"))\n",
    "    return record.description, str(record.seq)\n",
    "\n",
    "def remove_insertions(sequence: str) -> str:\n",
    "    \"\"\" Removes any insertions into the sequence. Needed to load aligned sequences in an MSA. \"\"\"\n",
    "    return sequence.translate(translation)\n",
    "    \n",
    "def read_msa(filename: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\" Reads the sequences from an MSA file, automatically removes insertions.\"\"\"\n",
    "    return [(record.description, remove_insertions(str(record.seq))) for record in SeqIO.parse(filename, \"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e50b61-4eac-47c7-86c4-e573b467de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "msas = {\n",
    "    \"1a3a\": read_msa(\"./data/1a3a_1_A.a3m\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d054d363-eb46-4502-82e1-9444343879d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sequences from the MSA to maximize the hamming distance\n",
    "# Alternatively, can use hhfilter \n",
    "def greedy_select(msa: List[Tuple[str, str]], num_seqs: int, mode: str = \"max\") -> List[Tuple[str, str]]:\n",
    "    assert mode in (\"max\", \"min\")\n",
    "    if len(msa) <= num_seqs:\n",
    "        return msa\n",
    "    \n",
    "    array = np.array([list(seq) for _, seq in msa], dtype=np.bytes_).view(np.uint8)\n",
    "\n",
    "    optfunc = np.argmax if mode == \"max\" else np.argmin\n",
    "    all_indices = np.arange(len(msa))\n",
    "    indices = [0]\n",
    "    pairwise_distances = np.zeros((0, len(msa)))\n",
    "    for _ in range(num_seqs - 1):\n",
    "        dist = cdist(array[indices[-1:]], array, \"hamming\")\n",
    "        pairwise_distances = np.concatenate([pairwise_distances, dist])\n",
    "        shifted_distance = np.delete(pairwise_distances, indices, axis=1).mean(0)\n",
    "        shifted_index = optfunc(shifted_distance)\n",
    "        index = np.delete(all_indices, indices)[shifted_index]\n",
    "        indices.append(index)\n",
    "    indices = sorted(indices)\n",
    "    return [msa[idx] for idx in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "834b2399-2711-4831-86c0-7ec20cbfaad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_transformer, msa_transformer_alphabet = esm.pretrained.esm_msa1b_t12_100M_UR50S()\n",
    "msa_transformer = msa_transformer.eval()\n",
    "msa_transformer_batch_converter = msa_transformer_alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b869fb8-f031-4545-8345-68eb5abfc695",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_transformer_predictions = {}\n",
    "msa_transformer_results = []\n",
    "for name, inputs in msas.items():\n",
    "    inputs = greedy_select(inputs, num_seqs=128) # can change this to pass more/fewer sequences\n",
    "    msa_transformer_batch_labels, msa_transformer_batch_strs, msa_transformer_batch_tokens = msa_transformer_batch_converter([inputs])\n",
    "    msa_transformer_batch_tokens = msa_transformer_batch_tokens.to(next(msa_transformer.parameters()).device)\n",
    "    y = msa_transformer(msa_transformer_batch_tokens, repr_layers=[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "677fbe43-885e-4112-8a00-bb109ae9203b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 146, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['representations'][12].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
